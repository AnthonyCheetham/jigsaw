{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal is to get the data from the csv files and put it all into one database\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "import scraper_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to database\n"
     ]
    }
   ],
   "source": [
    "# And connect to the database we'll use\n",
    "def connect_to_db():\n",
    "    try:\n",
    "        conn = psycopg2.connect(\"dbname='mypuzzle' user='postgres' host='localhost' password='gwv251'\")\n",
    "        cursor = conn.cursor()\n",
    "        print(\"Connected to database\")\n",
    "    except:\n",
    "        print(\"Unable to connect to database!\")\n",
    "    return conn\n",
    "conn = connect_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPLOAD URLS\n",
    "product_urls = np.loadtxt('1000_piece/product_urls.txt',dtype=str)\n",
    "\n",
    "# Upload to db\n",
    "# for url in product_urls:\n",
    "#     query = \"\"\"INSERT INTO public.products (product_url) \n",
    "#     VALUES  ('{0}')\"\"\".format(url)\n",
    "#     cursor.execute(query)\n",
    "# conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPLOAD METADATA\n",
    "reviews_df = scraper_tools.get_database()\n",
    "\n",
    "n_products = reviews_df.shape[0]\n",
    "# Fix some columns:\n",
    "star_rating_num = np.zeros((n_products))\n",
    "price_num = np.zeros((n_products))\n",
    "n_reviews = np.zeros((n_products))\n",
    "details = []\n",
    "for ix in range(n_products):\n",
    "    # Fix the star rating\n",
    "    x = reviews_df['star_rating'][ix]\n",
    "    if x != x: # Handle nans in shady way\n",
    "        x = 0\n",
    "    else:\n",
    "        x = x[0:3]\n",
    "    star_rating_num[ix] = float(x)\n",
    "\n",
    "    # Fix the price\n",
    "    price = reviews_df['Price'][ix]\n",
    "    if price != price or len(price) <3:\n",
    "        price = '$0.00'\n",
    "    price = price.strip().replace('$','')\n",
    "    price = float(price)\n",
    "    price_num[ix] = price\n",
    "    \n",
    "    # Fix the customer reviews\n",
    "    n_rev = reviews_df['n_reviews'][ix]\n",
    "    if n_rev != n_rev:\n",
    "        n_rev = -1\n",
    "    else:\n",
    "        n_rev = n_rev.strip().replace('customer review','').replace('s','')\n",
    "        n_rev = int(n_rev)\n",
    "    n_reviews[ix] = n_rev\n",
    "    \n",
    "    d = reviews_df['details'][ix]\n",
    "    d = d.replace(\"', '\",'. ').replace('[','').replace(']','').replace('..','')\n",
    "    details.append(d)\n",
    "# Save to db\n",
    "for ix in range(n_products):\n",
    "    row = reviews_df.iloc[ix]\n",
    "    url = product_urls[ix]\n",
    "    \n",
    "    query = \"\"\"UPDATE public.products \n",
    "    SET name = $${1}$$, n_reviews = {2}, price = {3}, brand = $${4}$$,\n",
    "    img_url = $${5}$$, star_rating = $${6}$$, details = $${7}$$\n",
    "    WHERE product_url = $${0}$$\n",
    "    \"\"\".format(url,row['Name'],n_reviews[ix],price_num[ix],row['Brand'],\n",
    "               row['img_url'],star_rating_num[ix],details[ix])\n",
    "    cursor.execute(query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to database\n",
      "Cleaning reviews table!\n",
      "not found! ['https://amazon.com/Buffalo-Games-Signature-Collection-Cinque/dp/B00ITTI3VW'\n",
      " 'https://amazon.com/Buffalo-Games-Darrell-Jigsaw-Puzzle/dp/B00WOZBOGS'\n",
      " 'https://amazon.com/Buffalo-Games-Marine-Bubbles-Jigsaw/dp/B07D8JKDRN'\n",
      " ...\n",
      " 'https://amazon.com/Midwest-Products-9283-Nitsche-Searching/dp/B006LWPQ46'\n",
      " 'https://amazon.com/Schmidt-SCH58151-Theresa-Jigsaw-1000-Piece/dp/B005JB9HOU'\n",
      " 'https://amazon.com/Aquarius-Peace-Chance-Jigsaw-Puzzle/dp/B002WVD3HM']\n"
     ]
    }
   ],
   "source": [
    "# Now save the reviews in the second table\n",
    "import glob, os\n",
    "review_files = glob.glob('1000_piece/product*.csv')\n",
    "\n",
    "def clean_review_db(conn):\n",
    "    print('Cleaning reviews table!')\n",
    "    # Delete entries\n",
    "    cur = conn.cursor()\n",
    "    query = \"DELETE FROM public.reviews\"\n",
    "    cur.execute(query)\n",
    "    \n",
    "    # Reset index\n",
    "    query2 = \"\"\"ALTER SEQUENCE reviews_review_index_seq RESTART WITH 1\"\"\"\n",
    "    cur.execute(query2)\n",
    "    \n",
    "    conn.commit()\n",
    "\n",
    "conn.close()\n",
    "conn = connect_to_db()\n",
    "cursor = conn.cursor()\n",
    "clean_review_db(conn)\n",
    "# Loop through \n",
    "for ix,url in enumerate(product_urls):\n",
    "    review_file = '1000_piece/product_{0:05}.csv'.format(ix)\n",
    "    if os.path.exists(review_file):\n",
    "        df = pd.read_csv(review_file)\n",
    "        reviews = df['Reviews']\n",
    "        ratings = df['ReviewRatings']\n",
    "    else:\n",
    "        print('not found!',url)\n",
    "        continue\n",
    "        \n",
    "    #Find out the product index\n",
    "    query = \"\"\" SELECT products.product_index FROM public.products\n",
    "        WHERE product_url = $${0}$$\n",
    "        \"\"\".format(url)\n",
    "    cursor.execute(query)\n",
    "    prod_ix = cursor.fetchone()[0]\n",
    "    \n",
    "    # Save to the database!\n",
    "    n_reviews = reviews.shape[0]\n",
    "    for r_ix in range(n_reviews):\n",
    "        # Clean the text a bit\n",
    "        clean_text = reviews[r_ix]\n",
    "        clean_text = clean_text.replace('$','')\n",
    "        clean_text = clean_text.replace(':)','')\n",
    "        \n",
    "        query = \"\"\"INSERT INTO public.reviews (product_index,review,rating) \n",
    "          VALUES  ({0},$${1}$$,{2})\n",
    "           \"\"\".format(prod_ix,clean_text,ratings[r_ix])\n",
    "        try:\n",
    "            cursor.execute(query)\n",
    "        except:\n",
    "            print('bad query: ',prod_ix[0],ix,query)\n",
    "            print(clean_text[r_ix])\n",
    "    if (ix % 10) == 0:\n",
    "        conn.commit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
