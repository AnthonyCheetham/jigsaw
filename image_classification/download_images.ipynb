{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import psycopg2\n",
    "# import nlp_tools\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "import time\n",
    "import scipy\n",
    "import warnings \n",
    "import requests\n",
    "import shutil\n",
    "  \n",
    "warnings.filterwarnings(action = 'ignore') \n",
    "\n",
    "##Connect to database\n",
    "# conn = nlp_tools.connect_to_db()\n",
    "engine = create_engine('postgresql://postgres:gwv251@localhost/mypuzzle',echo=False)\n",
    "\n",
    "data = pd.read_sql('SELECT * FROM products ORDER BY product_index ASC', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://images-na.ssl-images-amazon.com/images/I/81uaKTSk-xL._SL1200_.jpg\n"
     ]
    }
   ],
   "source": [
    "# Get all of the images\n",
    "for ix in np.arange(1227,1228):\n",
    "    url = data['img_url'][ix]\n",
    "    if (url == 'nan'):\n",
    "        continue\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    path = 'new_ims/'+str(ix)+'.jpg'\n",
    "    \n",
    "    if r.status_code == 200:\n",
    "        with open(path, 'wb') as f:\n",
    "            for chunk in r:\n",
    "                f.write(chunk) \n",
    "\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "1999\n"
     ]
    }
   ],
   "source": [
    "print(url != 'nan')\n",
    "print(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Darrell Bush : 18\n",
      "Wysocki : 56\n",
      "Stewart : 21\n",
      "Pinson : 12\n",
      "Thompson : 16\n",
      "Kinkade : 78\n",
      "Haasteren : 65\n",
      "artist labelled: 266 0.044333333333333336\n"
     ]
    }
   ],
   "source": [
    "# Now split them up by artist\n",
    "def find_word(word,sentence):\n",
    "    \"\"\" Keyword search algorithm that finds exact word matching only!\"\"\"\n",
    "    if ' '+word.lower()+' ' in sentence.lower():\n",
    "        return True\n",
    "    elif sentence.lower().endswith(' '+word.lower()) or sentence.lower().startswith(word.lower()+' '):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "artists = ['Darrell Bush','Wysocki','Stewart','Pinson','Thompson','Kinkade','Haasteren']\n",
    "n_artists = len(artists)\n",
    "artist_counts = np.zeros(n_artists,dtype=int)\n",
    "for ix in np.arange(0,6000):\n",
    "    im_f = 'new_ims/'+str(ix)+'.jpg'\n",
    "    \n",
    "    name = data['name'][ix]\n",
    "    for n_ix,artist in enumerate(artists):\n",
    "        artist_counts[n_ix] += find_word(artist,name)\n",
    "#         print(ix,find_word('Darrell Bush',name),name)\n",
    "\n",
    "for n_ix,artist in enumerate(artists):\n",
    "    print(artist,':',artist_counts[n_ix])\n",
    "n_artist_labelled = artist_counts.sum()\n",
    "print('artist labelled:',n_artist_labelled,n_artist_labelled/(ix+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_ims/1574.jpg new_ims/abstract/1574.jpg Ravensburger Time for Lunch - 1000 Piece Jigsaw Puzzle for Adults â€“ Every Piece is Unique, Softclick Technology Means Pieces Fit Together Perfectly\n",
      "new_ims/2037.jpg new_ims/abstract/2037.jpg White Mountain Puzzles - Classic Lunch Boxes - 1,000 Piece Jigsaw Puzzle\n",
      "new_ims/4093.jpg new_ims/abstract/4093.jpg Ravensburger 1000 Piece Premium Puzzle Featuring Softclick Technology - Time for Lunch By Artist Lori Schory - Artwork Features Various Birds and Butterflies Around a Birdhouse\n"
     ]
    }
   ],
   "source": [
    "# Put all jigsaws by an artist into a directory\n",
    "for ix,n in enumerate(data['name']):\n",
    "    is_true = find_word(\"lunch\",n)\n",
    "    if is_true:\n",
    "#         f = glob.glob('storage/*/'+str(ix)+'.jpg')\n",
    "        f = glob.glob('new_ims/'+str(ix)+'.jpg')\n",
    "        if len(f) ==1:\n",
    "            f = f[0]\n",
    "#             new_f = f.replace('/hand/','/licensed/')\n",
    "#             new_f = f.replace('storage/','storage/licensed/')\n",
    "            new_f = f.split('/')\n",
    "            new_f = new_f[0]+'/abstract/'+new_f[-1]\n",
    "            print(f,new_f,n)\n",
    "            shutil.move(f,new_f)\n",
    "#         print(ix,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 moved back\n",
      "0 moved back\n",
      "0 moved back\n",
      "0 moved back\n",
      "0 moved back\n",
      "0 moved back\n",
      "0 moved back\n",
      "0 moved back\n",
      "0 moved back\n",
      "0 moved back\n",
      "0 moved back\n",
      "0 moved back\n",
      "15 5 5\n",
      "102 34 34\n",
      "102 34 34\n",
      "78 26 27\n"
     ]
    }
   ],
   "source": [
    "# Now split them up\n",
    "import glob, shutil\n",
    "import numpy as np\n",
    "import time\n",
    "np.random.seed(42)\n",
    "\n",
    "train_frac = 0.6\n",
    "test_frac = 0.2\n",
    "eval_frac = 0.2\n",
    "# Tried to put \"map\" but resnet said they were collages, so I merged them.\n",
    "# Also removed hand_wysocki with hand, and weird_shape with everything else\n",
    "categories = ['abstract','collage','hand','photo']\n",
    "\n",
    "# Reset\n",
    "for wdir in categories:\n",
    "    for d in ['train','test','valid']:\n",
    "        fs = glob.glob(d+'/'+wdir+'/*.jpg')\n",
    "        print(len(fs),'moved back')\n",
    "        for f in fs:\n",
    "            new_fn = f.split('/')\n",
    "            new_fn = 'storage/'+new_fn[-2]+'/'+new_fn[-1]\n",
    "            shutil.move(f,new_fn)\n",
    "\n",
    "time.sleep(0.1)\n",
    "\n",
    "# raise Exception\n",
    "np.random.seed(0)\n",
    "for wdir in categories:\n",
    "    fs = glob.glob('storage/'+wdir+'/'+'*.jpg')\n",
    "    # Only take the first 100 if there are too many\n",
    "    fs = fs[0:170]\n",
    "    n = len(fs)\n",
    "    # Shuffle the order\n",
    "    np.random.shuffle(fs)\n",
    "    \n",
    "    # Pick some for the train set\n",
    "    cut_train = int(n*train_frac)\n",
    "    cut_test = int(n*(train_frac+test_frac))\n",
    "    fs_train = fs[0:cut_train]\n",
    "    fs_test = fs[cut_train:cut_test]\n",
    "    fs_eval = fs[cut_test:]\n",
    "    print(len(fs_train),len(fs_test),len(fs_eval))\n",
    "    for f in fs_train:\n",
    "        # Move them\n",
    "        new_fn = f.split('/')\n",
    "        new_fn = 'train/'+wdir+'/'+new_fn[2]\n",
    "        shutil.move(f,new_fn)\n",
    "\n",
    "    for f in fs_test:\n",
    "        # Move them\n",
    "        new_fn = f.split('/')\n",
    "        new_fn = 'test/'+wdir+'/'+new_fn[2]\n",
    "        shutil.move(f,new_fn)\n",
    "    \n",
    "    for f in fs_eval:\n",
    "        # Move them\n",
    "        new_fn = f.split('/')\n",
    "        new_fn = 'valid/'+wdir+'/'+new_fn[2]\n",
    "        shutil.move(f,new_fn)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Educa Taxi No. 1 New York Puzzle (1000 Piece)\n"
     ]
    }
   ],
   "source": [
    "print(data['name'][3408])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 moved back\n",
      "22 moved back\n",
      "22 moved back\n",
      "32 moved back\n",
      "11 moved back\n",
      "11 moved back\n",
      "19 moved back\n",
      "7 moved back\n",
      "7 moved back\n",
      "25 moved back\n",
      "8 moved back\n",
      "9 moved back\n",
      "102 moved back\n",
      "34 moved back\n",
      "34 moved back\n",
      "55 moved back\n",
      "18 moved back\n",
      "19 moved back\n",
      "85 moved back\n",
      "29 moved back\n",
      "29 moved back\n",
      "66 22 22\n",
      "32 11 11\n",
      "19 7 7\n",
      "25 8 9\n",
      "102 34 34\n",
      "55 18 19\n",
      "85 29 29\n"
     ]
    }
   ],
   "source": [
    "# Now split them up\n",
    "#######\n",
    "# THEME\n",
    "#######\n",
    "import glob, shutil\n",
    "import numpy as np\n",
    "import time\n",
    "np.random.seed(42)\n",
    "\n",
    "train_frac = 0.6\n",
    "test_frac = 0.2\n",
    "eval_frac = 0.2\n",
    "\n",
    "categories = ['animals','art','fantasy','food','landscape','licensed','towns_and_cities']\n",
    "\n",
    "# Reset\n",
    "for wdir in categories:\n",
    "    for d in ['train_theme','test_theme','valid_theme']:\n",
    "        fs = glob.glob(d+'/'+wdir+'/*.jpg')\n",
    "        print(len(fs),'moved back')\n",
    "        for f in fs:\n",
    "            new_fn = f.split('/')\n",
    "            new_fn = 'storage_theme/'+new_fn[-2]+'/'+new_fn[-1]\n",
    "            shutil.move(f,new_fn)\n",
    "\n",
    "time.sleep(0.1)\n",
    "\n",
    "# raise Exception\n",
    "np.random.seed(0)\n",
    "for wdir in categories:\n",
    "    fs = glob.glob('storage_theme/'+wdir+'/'+'*.jpg')\n",
    "    # Only take the first 100 if there are too many\n",
    "    fs = fs[0:170]\n",
    "    n = len(fs)\n",
    "    # Shuffle the order\n",
    "    np.random.shuffle(fs)\n",
    "    \n",
    "    # Pick some for the train set\n",
    "    cut_train = int(n*train_frac)\n",
    "    cut_test = int(n*(train_frac+test_frac))\n",
    "    fs_train = fs[0:cut_train]\n",
    "    fs_test = fs[cut_train:cut_test]\n",
    "    fs_eval = fs[cut_test:]\n",
    "    print(len(fs_train),len(fs_test),len(fs_eval))\n",
    "    for f in fs_train:\n",
    "        # Move them\n",
    "        new_fn = f.split('/')\n",
    "        new_fn = 'train_theme/'+wdir+'/'+new_fn[2]\n",
    "        shutil.move(f,new_fn)\n",
    "\n",
    "    for f in fs_test:\n",
    "        # Move them\n",
    "        new_fn = f.split('/')\n",
    "        new_fn = 'test_theme/'+wdir+'/'+new_fn[2]\n",
    "        shutil.move(f,new_fn)\n",
    "    \n",
    "    for f in fs_eval:\n",
    "        # Move them\n",
    "        new_fn = f.split('/')\n",
    "        new_fn = 'valid_theme/'+wdir+'/'+new_fn[2]\n",
    "        shutil.move(f,new_fn)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['product_index', 'name', 'n_reviews', 'price', 'brand', 'img_url',\n",
      "       'details', 'star_rating', 'product_url'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
